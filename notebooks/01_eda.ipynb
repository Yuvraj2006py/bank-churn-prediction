{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exploratory Data Analysis - Bank Churn Dataset\n",
        "\n",
        "This notebook performs comprehensive exploratory data analysis on the bank churn dataset to understand:\n",
        "- Dataset structure and data quality\n",
        "- Distribution of features\n",
        "- Relationships between features and churn\n",
        "- Key insights for model development\n",
        "\n",
        "## Table of Contents\n",
        "1. [Data Loading and Initial Inspection](#1-data-loading-and-initial-inspection)\n",
        "2. [Data Quality Assessment](#2-data-quality-assessment)\n",
        "3. [Target Variable Analysis](#3-target-variable-analysis)\n",
        "4. [Univariate Analysis](#4-univariate-analysis)\n",
        "5. [Bivariate Analysis](#5-bivariate-analysis)\n",
        "6. [Correlation Analysis](#6-correlation-analysis)\n",
        "7. [Key Insights and Conclusions](#7-key-insights-and-conclusions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import sys\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "\n",
        "# Add src directory to path for imports\n",
        "sys.path.append(str(Path('../').resolve()))\n",
        "from src.utils import (\n",
        "    load_data, get_data_overview, get_statistical_summary,\n",
        "    check_class_imbalance, plot_target_distribution,\n",
        "    plot_numeric_distributions, plot_categorical_analysis,\n",
        "    plot_correlation_matrix, get_feature_importance_correlation,\n",
        "    validate_data_quality\n",
        ")\n",
        "\n",
        "# Configure display options\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', 100)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', 50)\n",
        "\n",
        "# Set plotting style\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "plt.rcParams['font.size'] = 10\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n",
        "print(f\"Working directory: {os.getcwd()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Loading and Initial Inspection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "data_path = '../data/Churn Modeling.csv'\n",
        "df = load_data(data_path)\n",
        "\n",
        "print(f\"Dataset loaded successfully!\")\n",
        "print(f\"Shape: {df.shape}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get comprehensive overview\n",
        "overview = get_data_overview(df)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"DATASET OVERVIEW\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Shape: {overview['shape']} (rows, columns)\")\n",
        "print(f\"\\nColumns ({len(overview['columns'])}):\")\n",
        "for col in overview['columns']:\n",
        "    print(f\"  - {col}\")\n",
        "print(f\"\\nMemory Usage: {overview['memory_usage_mb']:.2f} MB\")\n",
        "print(f\"\\nDuplicate Rows: {overview['duplicate_rows']}\")\n",
        "print(f\"\\nNumeric Columns: {overview['numeric_columns']}\")\n",
        "print(f\"\\nCategorical Columns: {overview['categorical_columns']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display data types and basic info\n",
        "print(\"=\" * 60)\n",
        "print(\"DATA TYPES\")\n",
        "print(\"=\" * 60)\n",
        "print(df.dtypes)\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"DATA INFO\")\n",
        "print(\"=\" * 60)\n",
        "df.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display descriptive statistics\n",
        "print(\"=\" * 60)\n",
        "print(\"DESCRIPTIVE STATISTICS\")\n",
        "print(\"=\" * 60)\n",
        "df.describe()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Quality Assessment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Validate data quality\n",
        "quality_issues = validate_data_quality(df, target_col='Exited')\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"DATA QUALITY ASSESSMENT\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Check for missing values\n",
        "if quality_issues['missing_values']:\n",
        "    print(\"\\nMissing Values Found:\")\n",
        "    for col, count in quality_issues['missing_values'].items():\n",
        "        percentage = (count / len(df)) * 100\n",
        "        print(f\"  - {col}: {count} ({percentage:.2f}%)\")\n",
        "else:\n",
        "    print(\"\\n✓ No missing values found!\")\n",
        "\n",
        "# Check for duplicates\n",
        "if quality_issues['duplicates'] > 0:\n",
        "    print(f\"\\n⚠ Warning: {quality_issues['duplicates']} duplicate rows found\")\n",
        "else:\n",
        "    print(\"\\n✓ No duplicate rows found!\")\n",
        "\n",
        "# Check target variable\n",
        "if quality_issues['invalid_target_values']:\n",
        "    print(f\"\\n⚠ {quality_issues['invalid_target_values']}\")\n",
        "else:\n",
        "    print(\"\\n✓ Target variable values are valid (0 or 1)\")\n",
        "\n",
        "# Check for outliers\n",
        "if quality_issues['outliers']:\n",
        "    print(\"\\nOutliers detected (using IQR method):\")\n",
        "    for col, count in quality_issues['outliers'].items():\n",
        "        percentage = (count / len(df)) * 100\n",
        "        print(f\"  - {col}: {count} outliers ({percentage:.2f}%)\")\n",
        "else:\n",
        "    print(\"\\n✓ No significant outliers detected\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Target Variable Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze target variable distribution\n",
        "target_analysis = check_class_imbalance(df, target_col='Exited')\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"TARGET VARIABLE ANALYSIS\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nClass Distribution:\")\n",
        "for class_val, count in target_analysis['counts'].items():\n",
        "    prop = target_analysis['proportions'][class_val]\n",
        "    label = \"Churned\" if class_val == 1 else \"Retained\"\n",
        "    print(f\"  {label} ({class_val}): {count} ({prop:.2%})\")\n",
        "\n",
        "print(f\"\\nImbalance Ratio: {target_analysis['imbalance_ratio']:.3f}\")\n",
        "if target_analysis['is_imbalanced']:\n",
        "    print(\"⚠ Dataset is imbalanced - consider using techniques like SMOTE or class weights\")\n",
        "else:\n",
        "    print(\"✓ Dataset is relatively balanced\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize target distribution\n",
        "fig = plot_target_distribution(df, target_col='Exited', figsize=(12, 5))\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Univariate Analysis\n",
        "\n",
        "### 4.1 Numerical Features Distribution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get statistical summary by target variable\n",
        "summary_stats = get_statistical_summary(df, target_col='Exited')\n",
        "print(\"=\" * 60)\n",
        "print(\"STATISTICAL SUMMARY BY CHURN STATUS\")\n",
        "print(\"=\" * 60)\n",
        "summary_stats\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot distributions of numeric features by churn status\n",
        "fig = plot_numeric_distributions(df, target_col='Exited', figsize=(18, 12))\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Detailed analysis of key numerical features\n",
        "key_features = ['CreditScore', 'Age', 'Balance', 'EstimatedSalary', 'Tenure', 'NumOfProducts']\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for idx, feature in enumerate(key_features):\n",
        "    ax = axes[idx]\n",
        "    \n",
        "    # Create histogram with KDE\n",
        "    for exited in [0, 1]:\n",
        "        label = 'Retained' if exited == 0 else 'Churned'\n",
        "        data = df[df['Exited'] == exited][feature]\n",
        "        ax.hist(data, alpha=0.6, label=label, bins=30, density=True)\n",
        "    \n",
        "    ax.set_xlabel(feature)\n",
        "    ax.set_ylabel('Density')\n",
        "    ax.set_title(f'Distribution of {feature} by Churn Status')\n",
        "    ax.legend()\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2 Categorical Features Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze categorical features\n",
        "categorical_cols = ['Geography', 'Gender']\n",
        "fig = plot_categorical_analysis(df, categorical_cols, target_col='Exited', figsize=(14, 5))\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Detailed categorical analysis with counts\n",
        "print(\"=\" * 60)\n",
        "print(\"CATEGORICAL FEATURES ANALYSIS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for col in categorical_cols:\n",
        "    print(f\"\\n{col}:\")\n",
        "    print(\"-\" * 40)\n",
        "    crosstab = pd.crosstab(df[col], df['Exited'], margins=True)\n",
        "    crosstab_pct = pd.crosstab(df[col], df['Exited'], normalize='index') * 100\n",
        "    print(crosstab)\n",
        "    print(f\"\\nChurn Rates by {col}:\")\n",
        "    for val in df[col].unique():\n",
        "        churn_rate = df[df[col] == val]['Exited'].mean()\n",
        "        count = len(df[df[col] == val])\n",
        "        print(f\"  {val}: {churn_rate:.2%} (n={count})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze binary features\n",
        "binary_features = ['HasCrCard', 'IsActiveMember']\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "for idx, feature in enumerate(binary_features):\n",
        "    ax = axes[idx]\n",
        "    \n",
        "    # Calculate churn rates\n",
        "    churn_rates = df.groupby(feature)['Exited'].agg(['mean', 'count'])\n",
        "    \n",
        "    # Create bar plot\n",
        "    bars = ax.bar(churn_rates.index.astype(str), churn_rates['mean'], \n",
        "                  color=sns.color_palette('viridis', len(churn_rates)))\n",
        "    ax.set_xlabel(feature)\n",
        "    ax.set_ylabel('Churn Rate')\n",
        "    ax.set_title(f'Churn Rate by {feature}')\n",
        "    ax.set_ylim([0, 1])\n",
        "    \n",
        "    # Add labels\n",
        "    for i, (bar, count) in enumerate(zip(bars, churn_rates['Count'])):\n",
        "        height = bar.get_height()\n",
        "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "               f'{height:.2%}\\n(n={count})',\n",
        "               ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Bivariate Analysis\n",
        "\n",
        "### 5.1 Age Groups Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create age groups\n",
        "df['AgeGroup'] = pd.cut(df['Age'], bins=[0, 30, 40, 50, 60, 100], \n",
        "                        labels=['<30', '30-40', '40-50', '50-60', '60+'])\n",
        "\n",
        "# Analyze churn by age group\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Churn rate by age group\n",
        "churn_by_age = df.groupby('AgeGroup')['Exited'].agg(['mean', 'count'])\n",
        "bars = axes[0].bar(range(len(churn_by_age)), churn_by_age['mean'],\n",
        "                   color=sns.color_palette('viridis', len(churn_by_age)))\n",
        "axes[0].set_xticks(range(len(churn_by_age)))\n",
        "axes[0].set_xticklabels(churn_by_age.index)\n",
        "axes[0].set_ylabel('Churn Rate')\n",
        "axes[0].set_title('Churn Rate by Age Group')\n",
        "axes[0].set_ylim([0, 1])\n",
        "\n",
        "for i, (bar, count) in enumerate(zip(bars, churn_by_age['Count'])):\n",
        "    height = bar.get_height()\n",
        "    axes[0].text(bar.get_x() + bar.get_width()/2., height,\n",
        "                f'{height:.2%}\\n(n={count})',\n",
        "                ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "# Distribution of age by churn\n",
        "for exited in [0, 1]:\n",
        "    label = 'Retained' if exited == 0 else 'Churned'\n",
        "    axes[1].hist(df[df['Exited'] == exited]['Age'], alpha=0.6, \n",
        "                 label=label, bins=20)\n",
        "axes[1].set_xlabel('Age')\n",
        "axes[1].set_ylabel('Frequency')\n",
        "axes[1].set_title('Age Distribution by Churn Status')\n",
        "axes[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Churn Rates by Age Group:\")\n",
        "for age_group in df['AgeGroup'].cat.categories:\n",
        "    churn_rate = df[df['AgeGroup'] == age_group]['Exited'].mean()\n",
        "    count = len(df[df['AgeGroup'] == age_group])\n",
        "    print(f\"  {age_group}: {churn_rate:.2%} (n={count})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.2 Balance Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze balance and its relationship with churn\n",
        "print(\"=\" * 60)\n",
        "print(\"BALANCE ANALYSIS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Check zero balance customers\n",
        "zero_balance = df[df['Balance'] == 0]\n",
        "zero_balance_churn = zero_balance['Exited'].mean()\n",
        "print(f\"\\nCustomers with Zero Balance: {len(zero_balance)} ({len(zero_balance)/len(df):.2%})\")\n",
        "print(f\"Churn Rate (Zero Balance): {zero_balance_churn:.2%}\")\n",
        "\n",
        "non_zero_balance = df[df['Balance'] > 0]\n",
        "non_zero_balance_churn = non_zero_balance['Exited'].mean()\n",
        "print(f\"\\nCustomers with Non-Zero Balance: {len(non_zero_balance)} ({len(non_zero_balance)/len(df):.2%})\")\n",
        "print(f\"Churn Rate (Non-Zero Balance): {non_zero_balance_churn:.2%}\")\n",
        "\n",
        "# Create balance groups\n",
        "df['BalanceGroup'] = pd.cut(df['Balance'], \n",
        "                           bins=[-1, 0, 50000, 100000, 150000, float('inf')],\n",
        "                           labels=['0', '0-50K', '50K-100K', '100K-150K', '150K+'])\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Churn rate by balance group\n",
        "churn_by_balance = df.groupby('BalanceGroup')['Exited'].agg(['mean', 'count'])\n",
        "bars = axes[0].bar(range(len(churn_by_balance)), churn_by_balance['mean'],\n",
        "                   color=sns.color_palette('viridis', len(churn_by_balance)))\n",
        "axes[0].set_xticks(range(len(churn_by_balance)))\n",
        "axes[0].set_xticklabels(churn_by_balance.index, rotation=45, ha='right')\n",
        "axes[0].set_ylabel('Churn Rate')\n",
        "axes[0].set_title('Churn Rate by Balance Group')\n",
        "axes[0].set_ylim([0, 1])\n",
        "\n",
        "for i, (bar, count) in enumerate(zip(bars, churn_by_balance['Count'])):\n",
        "    height = bar.get_height()\n",
        "    axes[0].text(bar.get_x() + bar.get_width()/2., height,\n",
        "                f'{height:.2%}\\n(n={count})',\n",
        "                ha='center', va='bottom', fontsize=8)\n",
        "\n",
        "# Balance distribution\n",
        "for exited in [0, 1]:\n",
        "    label = 'Retained' if exited == 0 else 'Churned'\n",
        "    data = df[df['Exited'] == exited]['Balance']\n",
        "    axes[1].hist(data, alpha=0.6, label=label, bins=50)\n",
        "axes[1].set_xlabel('Balance')\n",
        "axes[1].set_ylabel('Frequency')\n",
        "axes[1].set_title('Balance Distribution by Churn Status')\n",
        "axes[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.3 Product and Tenure Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze number of products and tenure\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "# Churn rate by number of products\n",
        "churn_by_products = df.groupby('NumOfProducts')['Exited'].agg(['mean', 'count'])\n",
        "bars1 = axes[0, 0].bar(churn_by_products.index, churn_by_products['mean'],\n",
        "                       color=sns.color_palette('viridis', len(churn_by_products)))\n",
        "axes[0, 0].set_xlabel('Number of Products')\n",
        "axes[0, 0].set_ylabel('Churn Rate')\n",
        "axes[0, 0].set_title('Churn Rate by Number of Products')\n",
        "axes[0, 0].set_ylim([0, 1])\n",
        "for bar, count in zip(bars1, churn_by_products['Count']):\n",
        "    height = bar.get_height()\n",
        "    axes[0, 0].text(bar.get_x() + bar.get_width()/2., height,\n",
        "                   f'{height:.2%}\\n(n={count})',\n",
        "                   ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "# Churn rate by tenure\n",
        "churn_by_tenure = df.groupby('Tenure')['Exited'].agg(['mean', 'count'])\n",
        "bars2 = axes[0, 1].bar(churn_by_tenure.index, churn_by_tenure['mean'],\n",
        "                       color=sns.color_palette('viridis', len(churn_by_tenure)))\n",
        "axes[0, 1].set_xlabel('Tenure (Years)')\n",
        "axes[0, 1].set_ylabel('Churn Rate')\n",
        "axes[0, 1].set_title('Churn Rate by Tenure')\n",
        "axes[0, 1].set_ylim([0, 1])\n",
        "for bar, count in zip(bars2, churn_by_tenure['Count']):\n",
        "    height = bar.get_height()\n",
        "    axes[0, 1].text(bar.get_x() + bar.get_width()/2., height,\n",
        "                   f'{height:.2%}',\n",
        "                   ha='center', va='bottom', fontsize=7, rotation=90)\n",
        "\n",
        "# Distribution of products\n",
        "for exited in [0, 1]:\n",
        "    label = 'Retained' if exited == 0 else 'Churned'\n",
        "    data = df[df['Exited'] == exited]['NumOfProducts']\n",
        "    axes[1, 0].hist(data, alpha=0.6, label=label, bins=range(1, 6), align='left')\n",
        "axes[1, 0].set_xlabel('Number of Products')\n",
        "axes[1, 0].set_ylabel('Frequency')\n",
        "axes[1, 0].set_title('Number of Products Distribution')\n",
        "axes[1, 0].legend()\n",
        "\n",
        "# Distribution of tenure\n",
        "for exited in [0, 1]:\n",
        "    label = 'Retained' if exited == 0 else 'Churned'\n",
        "    data = df[df['Exited'] == exited]['Tenure']\n",
        "    axes[1, 1].hist(data, alpha=0.6, label=label, bins=range(0, 12), align='left')\n",
        "axes[1, 1].set_xlabel('Tenure (Years)')\n",
        "axes[1, 1].set_ylabel('Frequency')\n",
        "axes[1, 1].set_title('Tenure Distribution')\n",
        "axes[1, 1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Correlation Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot correlation matrix\n",
        "fig = plot_correlation_matrix(df, target_col='Exited', figsize=(12, 10))\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get feature importance based on correlation with target\n",
        "feature_corr = get_feature_importance_correlation(df, target_col='Exited')\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"FEATURE CORRELATION WITH TARGET (Exited)\")\n",
        "print(\"=\" * 60)\n",
        "print(feature_corr.to_string(index=False))\n",
        "\n",
        "# Visualize feature correlations\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "bars = ax.barh(feature_corr['Feature'], feature_corr['Correlation'],\n",
        "               color=sns.color_palette('viridis', len(feature_corr)))\n",
        "ax.set_xlabel('Absolute Correlation with Churn')\n",
        "ax.set_title('Feature Importance (Correlation with Target)')\n",
        "ax.invert_yaxis()\n",
        "\n",
        "for i, (bar, corr) in enumerate(zip(bars, feature_corr['Correlation'])):\n",
        "    ax.text(corr, bar.get_y() + bar.get_height()/2,\n",
        "           f'{corr:.3f}',\n",
        "           ha='left', va='center', fontsize=9)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Key Insights and Conclusions\n",
        "\n",
        "### Summary of Findings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate summary insights\n",
        "print(\"=\" * 60)\n",
        "print(\"KEY INSIGHTS FROM EDA\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# 1. Dataset overview\n",
        "print(\"\\n1. DATASET CHARACTERISTICS:\")\n",
        "print(f\"   - Total records: {len(df):,}\")\n",
        "print(f\"   - Features: {len(df.columns) - 1} (excluding target)\")\n",
        "print(f\"   - No missing values detected\")\n",
        "print(f\"   - No duplicate records\")\n",
        "\n",
        "# 2. Target variable\n",
        "print(\"\\n2. TARGET VARIABLE (Churn):\")\n",
        "churn_rate = df['Exited'].mean()\n",
        "print(f\"   - Overall churn rate: {churn_rate:.2%}\")\n",
        "print(f\"   - Churned customers: {df['Exited'].sum():,}\")\n",
        "print(f\"   - Retained customers: {(df['Exited'] == 0).sum():,}\")\n",
        "if target_analysis['is_imbalanced']:\n",
        "    print(f\"   - ⚠ Dataset is imbalanced (ratio: {target_analysis['imbalance_ratio']:.3f})\")\n",
        "\n",
        "# 3. Geography\n",
        "print(\"\\n3. GEOGRAPHY:\")\n",
        "geo_churn = df.groupby('Geography')['Exited'].agg(['mean', 'count'])\n",
        "for geo, row in geo_churn.iterrows():\n",
        "    print(f\"   - {geo}: {row['mean']:.2%} churn rate (n={row['count']:,})\")\n",
        "\n",
        "# 4. Gender\n",
        "print(\"\\n4. GENDER:\")\n",
        "gender_churn = df.groupby('Gender')['Exited'].agg(['mean', 'count'])\n",
        "for gender, row in gender_churn.iterrows():\n",
        "    print(f\"   - {gender}: {row['mean']:.2%} churn rate (n={row['count']:,})\")\n",
        "\n",
        "# 5. Age\n",
        "print(\"\\n5. AGE:\")\n",
        "age_churn = df.groupby('AgeGroup')['Exited'].agg(['mean', 'count'])\n",
        "for age_group, row in age_churn.iterrows():\n",
        "    print(f\"   - {age_group}: {row['mean']:.2%} churn rate (n={row['count']:,})\")\n",
        "\n",
        "# 6. Active membership\n",
        "print(\"\\n6. ACTIVE MEMBERSHIP:\")\n",
        "active_churn = df.groupby('IsActiveMember')['Exited'].agg(['mean', 'count'])\n",
        "for active, row in active_churn.iterrows():\n",
        "    status = \"Active\" if active == 1 else \"Inactive\"\n",
        "    print(f\"   - {status}: {row['mean']:.2%} churn rate (n={row['count']:,})\")\n",
        "\n",
        "# 7. Balance\n",
        "print(\"\\n7. BALANCE:\")\n",
        "zero_bal_churn = df[df['Balance'] == 0]['Exited'].mean()\n",
        "non_zero_bal_churn = df[df['Balance'] > 0]['Exited'].mean()\n",
        "print(f\"   - Zero balance: {zero_bal_churn:.2%} churn rate\")\n",
        "print(f\"   - Non-zero balance: {non_zero_bal_churn:.2%} churn rate\")\n",
        "\n",
        "# 8. Top correlated features\n",
        "print(\"\\n8. TOP FEATURES CORRELATED WITH CHURN:\")\n",
        "top_features = feature_corr.head(5)\n",
        "for _, row in top_features.iterrows():\n",
        "    print(f\"   - {row['Feature']}: {row['Correlation']:.3f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"RECOMMENDATIONS FOR MODELING\")\n",
        "print(\"=\" * 60)\n",
        "print(\"1. Handle class imbalance using SMOTE or class weights\")\n",
        "print(\"2. Consider feature engineering for Age (age groups) and Balance (balance groups)\")\n",
        "print(\"3. Encode categorical variables (Geography, Gender)\")\n",
        "print(\"4. Scale numerical features for distance-based algorithms\")\n",
        "print(\"5. Focus on top correlated features: Age, Balance, IsActiveMember, Geography\")\n",
        "print(\"6. Consider interaction features (e.g., Age × Balance, Geography × IsActiveMember)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save cleaned dataset with engineered features for next phase\n",
        "df_cleaned = df.copy()\n",
        "\n",
        "# Save to CSV (optional - for use in next phase)\n",
        "# df_cleaned.to_csv('../data/churn_data_cleaned.csv', index=False)\n",
        "# print(\"Cleaned dataset saved successfully!\")\n",
        "\n",
        "print(\"EDA Complete! Ready for Phase 3: Data Preprocessing & Feature Engineering\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
